\chapter{Clase 4: 09/09}

\section{Algoritmo de Deutsch}

Volviendo a lo de la clase pasada, quién es $U_{f}$?

Si $f(0)=f(1)=0$ es la I

Si $f(0)=f(1)=1$ es $I_{A}\otimes\sigma_{xB}$ 

Si $f(0)=0$, $f(1)=1$ Control-NOT

Si $f(0)=1$, $f(1)=0$ un Control-NOT dado vuelta (el circulito chiquito
implica 2 $\sigma_{x}$


\section{Algoritmo de Deutsch - Joscza}

Ahora tengo $f:\{0,1\}^{\otimes n}\rightarrow\LLAVES{0,1}$ ie $f:\LLAVES{0,1,\dots,2^{n}-1}\rightarrow\LLAVES{0,1}$

$f$ puede ser constante $f(i)=0$ $\forall i$ o $f(i)=1$ $\forall i$
o balanceada $f(i)=0$ para mitad del dominio y $f(i)=1$ la otra
mitad. 

\textbf{Clásicamente:} se necesitan para saber si $f$ es constante o balanceada
$\frac{2^{n}}{2}+1$ evaluaciones de $f$. Es exponencialmente grande.

\textbf{Cuánticamente:} se necesita una evaluación de $f$. 

Cómo es el circuito?
\begin{center}
\begin{quantikz} \lstick[wires=4]{N-1} & \lstick{$\ket{0}$} & \gate{H} &  \gate[5]{U_f} & \gate{H} &\meter{} \\ & \lstick{$\ket{0}$} & \gate{H} &   & \gate{H} &\meter{} \\ & \lstick{$\ket{0}$} & \gate{H} &   & \gate{H} &\meter{} \\ & \lstick{$\ket{0}$} & \gate{H} &   & \gate{H} &\meter{} \\ \qw&\lstick{$\ket{1}$} & \gate{H} &   & \gate{H} &\meter{} \\ \end{quantikz}
\par\end{center}

$H^{\otimes n}\KET{00\dots0}=H\KET 0H\KET 0\otimes H\KET 0=\PARENTESIS{\KET 0+\KET 1}\PARENTESIS{\KET 0+\KET 1}\otimes\dots\PARENTESIS{\KET 0+\KET 1}$

\[
=\KET{0\dots0}+\KET{0\dots01}+\dots
\]

\[
=\sum_{j=0}^{2^{n}-1}\KET j
\]
esta es la base binaria

$U_{f}\KET{j,i}=\KET{j,i\oplus f(j)}$ luego si aplico $U_{f}\KET -=\KET -\:o\:-\KET -$. 

El estado 
\[
\underset{\KET{0\dots0}}{\KET 0}\KET 1\rightarrow\sum_{j=0}^{2^{n}-1}\KET j\KET -\underset{U_{f}}{\rightarrow}\sum_{j=0}^{2^{n}-1}\KET j(-1)^{f(j)}\KET -
\]

Habíamos dicho que $f(j)$ podía ser cte o balanceada, entonces cómo
nos damos cuenta en que caso estamos:

$=\begin{array}{cc}
\nnearrow & \text{cte: }\PARENTESIS{\sum_{j=0}^{2^{n}-1}\KET j}\KET -(-1)^{f(1)}\rightarrow\KET 0\KET -(-1)^{f(1)}\\
\\
\ssearrow & \text{balanceada: }\KET 1\KET -
\end{array}$

En resumen este circuito con una sola entrada genera todos estados
ortogonales, si $f$ es constante mido y me van a dar todos los qubits para
arriba ahora si $f$ es balanceada alguno me va a dar hacia abajo.

\textbf{¿Cuántos gates necesito para hacerlo? }vamos a ver que no
necesito tantos.

\section{Medidas generalizadas}

Nos basamos en el entrelazamiento para hacer medidas.

Tenemos \textbf{medidas proyectivas} $\LLAVES{P_{j},\:P_{j}P_{h}=\delta_{jh}P_{j},\;j=1,\dots,d\:\sum_{j}P_{j}=I}$
que tienen un observable asociado $O=\sum_{j}\lambda_{j}P_{j}$ ,
con $p(j)=\EXPECT{\psi}{\psi}{P_{j}}=q_{j}$ con $q_{j}$ la probabilidad
de medir j

El estado después de la medida 
\[
\KET{\psi}\rightarrow\frac{P_{j}\KET{\psi}}{\sqrt{q_{j}}}=\KET{\psi_{j}}=\KET j
\]
siendo $p(j)=\MODULO{C_{j}}^{2}=q_{j}$ si a $\KET{\psi}=\sum_{j}C_{j}\KET j$

Estos proyectores no tienen por que ser de rango uno.

\textbf{Medidas generalizadas} son de la forma $\LLAVES{M_{j},\:\sum_{j}M_{j}^{T}M_{j}=I,j=1,\dots,d}$

$p(j)=\EXPECT{\psi}{\psi}{M_{j}^{T}M_{j}}$ , luego 
\[
\sum_{j}p(j)=\EXPECT{\psi}{\psi}{\sum_{j}M_{j}^{T}M_{j}}=\BRAKETEO{\psi}{\psi}=1
\]
 

$M_{j}^{T}M_{j}$ es un operador hermítico, definido positivo

\[
\KET{\psi}\rightarrow\KET{\psi_{j}}=\frac{M_{j}\KET{\psi}}{\sqrt{q_{j}}}\:p(j)>0
\]

Proyectiva $M_{j}=P_{j}$, $M_{j}^{T}=P_{j}=M_{j}$, $M_{j}^{T}M_{j}=P_{j}$.

Asumiendo que uno solamente puede hacer medidas proyectivas

Sistema auxiliar llamado \textbf{ancilla }que puede ser 1 qubit o
un sistema de qubits.

\[
U(\KET{\psi}o\KET 0)=\sum_{j=1}^{d}M_{j}\KET{\psi}o\KET j
\]
ahora este gate va a generar estados entrelazados 
\begin{center}
\par\end{center}

\begin{quantikz}  \lstick{$\ket{\psi}$}  &  \gate[2]{U} &  \qw\rstick{$\alpha M_j\ket{\psi}$} \\ \lstick{$\ket{0}$} &  & \meter{} & \qw\rstick{$\ket{j}$}   \\ \end{quantikz}

U es unitario

$\BRA{\varphi}\BRA 0U^{\dagger}U\KET{\psi}\KET 0=\BRAKETEO{\varphi}{\psi}$
si $U$ es unitario

\[
\PARENTESIS{\sum_{j}\BRA{\varphi}M_{j}^{\dagger}\BRA j}\PARENTESIS{\sum_{j}M_{j}\KET{\psi}\KET 0}=\sum_{j}\EXPECT{\varphi}{\psi}{M_{j}^{\dagger}M_{j}}=\EXPECT{\varphi}{\psi}I=\BRAKETEO{\varphi}{\psi}
\]

La medida protectiva es $P_{j}=\PROYECT jj$ con $j=1,\dots,d$

\[
P(j)=\BRA{\psi}\BRA 0U^{\dagger}I\otimes P_{j}U\KET{\psi}\KET 0=\EXPECT{\psi}{\psi}{M_{j}^{\dagger}M_{j}}
\]


\subsubsection{Ejemplo qubit}

Medidas proyectivas es medir el spin en una dirección $\vec{S}\vec{n}$,
$\vec{S}=\frac{\hbar}{e}\vec{\sigma}$, podemos reescribir como $\vec{\sigma}\vec{n}$.
Ej. medir $\sigma_{z}$

Medidas generalizadas : $\LLAVES{M_{0}=\sqrt{p_{0}}\PROYECT 00,M_{1}=\sqrt{p_{1}}\PROYECT ++,M_{2}=\sqrt{p_{2}}\PROYECT{\bar{\psi}}{\bar{\psi}}}$
con $\KET +=\frac{\KET 0+\KET 1}{\sqrt{2}}$, lo que se tiene que
cumplir es que $M_{0}^{\dagger}M_{0}+M_{1}^{\dagger}M_{1}+M_{2}^{\dagger}M_{2}=I$

Si lo miramos en la esfera de bloch 

la suma de las flechas tiene que dar cero, recordar que la identidad
esta en el origen de la esfera. 

\subsubsection{Ej. distinción de estados no ortogonales}

Sup que una fuente emite el estado $\KET 0$ con probabilidad $1/2$
o el estado $\KET +=\frac{\KET 0+\KET 1}{\sqrt{2}}$ con probabilidad
$1/2$ el problema es que $\BRAKETEO +0=\frac{1}{\sqrt{2}}\neq0$. 

Midiendo en z $\LLAVES{\PROYECT 00,\PROYECT 11}$ si se obtiene estado
1 se que la fuente emitió el estado + porque es el único que tiene
estado 1, ahora bien si mido 0 no se porque los dos estados que meto
tienen 0.

$P(1)=\frac{1}{2}\frac{1}{2}=\frac{1}{4}=Tr\rho\PROYECT 11=\EXPECT 11{\rho}$

$P(0)=\frac{1}{2}+\frac{1}{4}=\frac{3}{4}=Tr\rho\PROYECT 00=\EXPECT 00{\rho}$

La estadistica que obtengo es la misma que tienendo el estado (esto
es lo que emite la fuente) $\rho=\frac{1}{2}\PROYECT 00+\frac{1}{2}\PROYECT ++$

$M=\LLAVES{\sqrt{p}\PROYECT 11,\sqrt{p}\PROYECT --,\sqrt{q}\PROYECT{\psi}{\psi}}$Si
mido 1 (es decir del primero) se que salió de la fuente el 0, si mido
2 (el segundo) se que salió el +, luego si mido 3 no sé que salió.
Tengo que agregar ese tercero para que sume la identidad:

\[
M_{1}^{\dagger}M_{1}+M_{2}^{\dagger}M_{2}+M_{3}^{\dagger}M_{3}=I
\]

\begin{center}
\includegraphics[scale=0.5]{pegado9}
\par\end{center}

Uno puede ver que el estado $\KET{\psi}=\cos\PARENTESIS{\frac{\theta}{2}}\KET 0+\sin\PARENTESIS{\frac{\theta}{2}}\KET 1$
con $\theta=\frac{\pi}{4}$

$p\PARENTESIS{\PROYECT 11+\PROYECT --}+q\PROYECT{\psi}{\psi}=I=\PROYECT 00+\PROYECT 11$

$2p+q=2$ de acá vamos a ver que $p=2-\sqrt{2}$.

$p(1)=Tr\PARENTESIS{\rho M_{1}^{\dagger}M_{1}}=p\frac{1}{4}$

$p(2)=Tr\PARENTESIS{\rho M_{2}^{\dagger}M_{2}}=p\frac{1}{4}$

$p(3)=Tr\PARENTESIS{\rho M_{3}^{\dagger}M_{3}}=1-p/2$

12.04 -12.05 se cayó internet

\subsection{¿Qué es una medida?}
\begin{center}
\includegraphics[scale=0.5]{\string"fig3 clase9-9\string".png}
\par\end{center}

Esto es una premedida ya que el resultado es un estado puro. Como
uno quiere medir en z no en x esto no me sirve.

Entonces agrego un tercer qubit con otro Control-NOT
\begin{center}
\includegraphics[scale=0.5]{\string"fig4 clase9-9\string".png}
\par\end{center}

Ahora esto si es una medida

$Tr_{E}\KET{\psi_{SME}}\BRA{\psi_{SME}}=Tr_{E}\PARENTESIS{\alpha\KET{000}+\beta\KET{111}}\PARENTESIS{\alpha^{*}\BRA{000}+\beta^{*}\BRA{111}}$

\[
=\MODULO{\alpha}^{2}\KET{00}\BRA{00}+\MODULO{\beta}^{2}\KET{11}\BRA{11}
\]

$\MODULO{\alpha}^{2}=\BRAKETEO{\psi}{10}\BRAKETEO{01}{\psi}$ $\MODULO{\beta}^{2}=\BRAKETEO{\psi}{11}\BRAKETEO{11}{\psi}$

El tercer estado me hace una decoherencia para que quede en un estado
mixto.

Uno tiene un sistema general cuántico $\KET{\psi_{S}}=\sum_{j}c_{j}\KET j$,
el sistema de medida originalmente $\KET{0_{M}}$ y el entorno en
un $\KET{0_{E}}$. 

$O_{s}=\sum_{j}j\PROYECT jj$ podemos pensar $U=e^{-i\frac{P_{M}}{\hbar}\otimes O_{S}}$
siendo $P_{M}$ el impulso del sistema. El sistema de medida es macroscópico
por ej una aguja que tiene un espectro continuo muy denso. Si aplico
\[
U\PARENTESIS{\KET{\psi_{s}}\KET{0_{M}}}=e^{-i\frac{P_{M}}{\hbar}\otimes O_{S}}\sum_{j}c_{j}\KET{j_{s}}\KET{0_{M}}=\sum_{j}e^{-i\frac{P_{M}}{\hbar}j}c_{j}\KET j\KET{0_{M}}
\]

\[
=\sum_{j}c_{j}\KET{j_{s}}\KET j
\]

usando que $e^{-i\frac{P_{M}}{\hbar}j}\KET{0_{M}}=\KET j$ es como
que es el estado asociado a que se mueva la aguja. Esto sucede porque
hay una interacción fuerte entre el sistema y la medida.

Luego de un cierto tiempo empieza a ocurrir algo en el entorno,

\[
\KET{\psi_{SME}}=\sum c_{j}\KET{j_{s}}\KET{j_{M}}\KET{j_{E}}
\]

Luego si tomo la traza parcial del sistema

\[
Tr_{E}\KET{\psi_{SME}}\BRA{\psi_{SME}}=\sum_{j}\MODULO{c_{j}}^{2}\KET{j_{S}}\EXPECT{j_{S}}{j_{m}}O\BRA{j_{m}}
\]


\chapter{Clase 5: 11/09}

\section{Medidas locales}

Tenemos un sistema bipartito $A.B$ en un estado general que se puede
escribir como 
\[
\KET{\psi_{AB}}=\sum_{i,j}c_{ij}\KET{i_{A}}\KET{j_{B}}
\]

Si hacemos una medida proyectiva en A: $\LLAVES{\PROYECT{i_{A}}{i_{A}}\otimes I_{B}=P_{i}^{A},\:i=1,\dots,d_{A}}$
con $O_{A}=\sum_{i}O_{A}\PROYECT{i_{A}}{i_{A}}$

\subsection*{1) 
\[
\protect\KET{\psi_{AB}}=\sum_{i}\protect\KET{i_{A}}\protect\PARENTESIS{\sum_{j=1}^{d_{B}}\protect\LLAVEABAJO{c_{ij}\protect\KET{j_{B}}}{\sqrt{p_{i}}\protect\KET{i_{B}}}}
\]
}

\[
=\sum_{i}\sqrt{p_{i}}\KET{i_{A}}\KET{i_{B}}
\]
Quién es $p_{i}$ y quién es $\KET{i_{B}}$

\[
\KET{i_{B}}=\frac{\sum_{j}c_{ij}\KET{j_{B}}}{\sqrt{p_{i}}}
\]
con $\sqrt{p_{i}}=\sqrt{\sum_{j}\MODULO{c_{ij}}^{2}}$

Al hacer una medida, quiero saber el estado posmedido si sale el resultado
i:

\[
\KET{\psi'_{AB}}=\frac{P_{i}\KET{\psi_{AB}}}{\sqrt{\EXPECT{\psi_{AB}}{\psi_{AB}}{P_{i}}}}=\frac{\sqrt{p_{i}}\KET{i_{A}}\KET{i_{B}}}{\sqrt{p_{i}}}
\]

La probabilidad de medir el estado i es 

\[
p(i)=\EXPECT{\psi_{AB}}{\psi_{AB}}{P_{i}}=p_{i}
\]

Tenemos 2 sistemas, entonces si mido en una base de A, este sistema
remoto B va a colapsar a un estado que depende de la medida que haga
en el sistema A. Si en B no se conoce el resultado de la medida en
A no va a afectar a las medidas locales. 
\begin{center}
\includegraphics{pegado11}
\par\end{center}

\subsection*{2)}

Si se hacen muchas medidas de un estado (tengo una máquina que me
hace muchas veces el mismo estado), el estado posmedido para el resultado
$i$ 

\[
\KET{\psi_{AB}}=\sum_{i}\sqrt{p_{i}}\KET{i_{A}}\KET{i_{B}}\overset{\text{colapsa a}}{\longrightarrow}\KET{i_{A}}\KET{i_{B}}\overset{\text{corresponde a un estado matriz densidad}}{\longrightarrow}\rho_{AB}=\KET{i_{A}}\KET{i_{B}}\BRA{i_{A}}\BRA{i_{B}}
\]

Estado posmedido promedio (sin posc-eleccion) 

\[
\rho'_{AB}=\sum_{i}p_{i}\KET{i_{A}}\KET{i_{B}}\BRA{i_{A}}\BRA{i_{B}}
\]

Es el estado que obtendría si tengo resultado $i$ por la probabilidad
de obtenerlo. Este estado es en concreto un proyector local

\[
\rho'_{AB}=\sum_{i}\hat{P}_{i}\rho_{AB}\hat{P}_{i}=\sum_{i}\PROYECT{i_{A}}{i_{A}}\otimes I_{B}\rho_{AB}\PROYECT{i_{A}}{i_{A}}\otimes I_{B}
\]

A qué va esto? Se supone que una fuente emite muchas veces el mismo
estado, las estadísticas que voy a obtener van a estar determinados
por $\rho'_{AB}$. Entonces que pasa si quiero obtener el valor medio
de un observable pormedido

\[
\VALMEDIO{O_{B}}'=Tr\rho'_{AB}\PARENTESIS{I_{A}\otimes O_{B}}=Tr\PARENTESIS{\rho'_{B}O_{B}}
\]
con $\rho'_{B}=Tr_{A}\rho'_{AB}=Tr_{A}\rho_{AB}$ porque $Tr_{A}\PARENTESIS{\rho'_{AB}}=Tr_{A}\PARENTESIS{\sum_{i}\hat{P}_{i}^{A}\rho_{AB}\hat{P}_{i}^{A}}=\sum_{i}Tr_{A}\rho_{AB}\hat{P}_{i}^{A}=Tr_{A}\rho_{AB}$
entonces el resultado es igual que si no hubiera medido en A.

Los estados posmedidos entonces tenemos a 
\[
\rho_{AB}=\KET{i_{A}}\KET{i_{B}}\BRA{i_{A}}\BRA{i_{B}}\rightarrow\text{estado puro}
\]

y al estado promedio 
\[
\rho'_{AB}=\sum_{i}p_{i}\KET{i_{A}}\KET{i_{B}}\BRA{i_{A}}\BRA{i_{B}}\rightarrow\text{estado mixto}
\]

Ahora el estado promedio en B

\[
Tr\PARENTESIS{\rho'_{AB}I_{A}\otimes O_{B}}=Tr_{B}\PARENTESIS{\LLAVEABAJO{Tr_{A}\rho'_{AB}}{\rho'_{B}}}O_{B}=Tr_{B}\rho'_{B}O_{B}=Tr_{B}\rho_{B}O_{B}
\]

El lado de A si cambia pero en la base de B el estado promedio no
cambia antes y después de la medida, debido a esto es que no tenemos
transmisión instantánea de la información. 

A tener en cuenta que $\KET{i_{B}}$ no son ortogonales, pero si hago
la medida en la base de Schmidt ahí si van a ser ortogonales. 

\subsection*{3) }

Si $\KET{\psi_{AB}}$ es entrelazado, con $dim(\mathcal{H}_{A})=dim(\HILBERT_{B})=d$
y su descomposición de Schmidt $\KET{\psi_{AB}}=\sum_{k=1}^{n_{s}}\sqrt{\lambda_{k}}\KET{k_{A}}\KET{k_{B}}$.

\paragraph*{Si $n_{s}=d$ (está máximamente entrelazado) entonces mediante una
medida en A es posible colapsar a un estado y un producto $\protect\KET{i_{A}}\protect\KET{i_{B}}$,
con $\protect\KET{i_{B}}$ arbitrario. Es decir con una medida local
en A podemos hacer colapsar al sistema B al estado que querramos. }

Ej 2 qubits, y miramos sobre la esfera de Bloch , midiendo localmente
en A en alguna base puedo hacer que el estado en el sistema B este
en cualquier punto sobre la esfera de Bloch.

Tras una medida local en A con resultado $i$, $\PROYECT{i_{A}}{i_{B}}\otimes I_{B}$
esa $i$ en el ket indica que es en otra base no en la de Schmidt

\[
\KET{\psi_{AB}}\rightarrow\frac{\PROYECT{i_{A}}{i_{B}}\otimes I_{B}\KET{\psi_{AB}}}{\sqrt{p_{i}}}=\sum_{k}\frac{\sqrt{\lambda_{k}}}{\sqrt{p_{i}}}\BRAKETEO{i_{A}}{k_{A}}\KET{i_{A}}\KET{k_{B}}
\]

\[
=\KET{i_{A}}\sum_{k}\frac{\sqrt{\lambda_{k}}}{\sqrt{p_{i}}}\BRAKETEO{i_{A}}{k_{A}}\KET{k_{B}}
\]

Entonces eligiendo la base de medida $i_{A}$ uno puede hacer que
estos coeficientes $\BRAKETEO{i_{A}}{k_{A}}$ valgan lo que uno quiera,
entonces podemos hacer colapsar el sistema al estado que querramos.
Esto lo puedo hacer si el estado tiene valor de Schmidt máximo y si
la $dim(\mathcal{H}_{A})\geq dim(\HILBERT_{B})$, sino voy a poder
colapsar solo a un subespacio de B. 

\subsubsection*{Resumamos los 3 ítems:}

\paragraph*{1) Una medida local destruye el entrelazamiento porque queda un estado
producto.}

\paragraph*{2) Tenemos el concepto de estado promedio, es un estado mixto aún
cuando el sistema original sea puro. La traza parcial sobre el estado
en el sistema no lo medimos es la misma que si no hubiéramos medido
en el otro sistema. No hay transmisión instantánea de la información.}

\paragraph*{3) En las medidas en coincidencia uno puede hacer que el fotón que
llegue a Marte termine en cualquier estado que yo quiera si viene
estado entrelazado. Una medida local va a afectar a una medida particular.}

\section{Paradoja de EPR (1935)}

A partir de los años 60 Bell, demostró que los valores medios que obtengo en
la mecánica cuántica son diferentes que los que se pueden obtener clásicamente. 

Consideramos un estado entrelazado de 2 qubits tipo singlete.

\[
\KET{\psi_{AB}}=\frac{\KET{01}-\KET{10}}{\sqrt{2}}\:\text{base de z}
\]

\[
=\frac{\KET{+-}-\KET{-+}}{\sqrt{2}}\;\text{base de x}
\]

\[
=\frac{\KET{0'1'}-\KET{1'0'}}{\sqrt{2}}\;\text{base cualquiera rotada}
\]

Usamos este estado porque tiene la particularidad de que se puede
escribir de la misma forma en muchas bases distintas. Esto se debe
a que tiene $S=0$ entonces es invariante frente a rotaciones.

Calculemos el valor medio de un observable local

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes I_{B}}=0
\]
porque tengo igual probabilidad de estar arriba que abajo. Igual que 

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{I_{A}\otimes\sigma_{z}^{B}}=0
\]

Estas no son la clase de medida a las que apunta EPR. Supongamos que
tenemos una medida en coincidencia: 
\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=-1
\]
Porque cuando uno está en 1 el otro está en -1 y al revés, entonces
el producto es siempre -1.

\[
\PARENTESIS{\frac{\BRA{01}-\BRA{10}}{\sqrt{2}}}\PARENTESIS{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}\PARENTESIS{\frac{\KET{01}-\KET{10}}{\sqrt{2}}}=
\]

Veamos que 
\[
\EXPECT{01}{01}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=\EXPECT 00{\sigma_{z}}\EXPECT 11{\sigma_{z}}=1.(-1)=-1
\]

\[
\EXPECT{01}{10}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=\EXPECT 01{\sigma_{z}}\EXPECT 10{\sigma_{z}}=0
\]

\[
\EXPECT{10}{01}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=0
\]

\[
\EXPECT{01}{01}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=\EXPECT 01{\sigma_{z}}\EXPECT 10{\sigma_{z}}=-1.1=1
\]

Finalmente 

\[
\PARENTESIS{\frac{\BRA{01}-\BRA{10}}{\sqrt{2}}}\PARENTESIS{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}\PARENTESIS{\frac{\KET{01}-\KET{10}}{\sqrt{2}}}=\frac{1}{2}\PARENTESIS{-1-1}=-1
\]

Con esto sólo no podemos ver el entrelazamiento porque lo podemos
ver en un sistema clásico, por ej tenemos 2 valijas en una pongo una
media roja y en la otra una media negra, mando una a marte y otra
la dejo en la tierra, al medir en marte se cual tengo en la tierra. 

Este valor medio lo puedo obtener con la traza

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=Tr\rho_{AB}\sigma_{z}^{A}\otimes\sigma_{z}^{B}
\]
 con $\rho_{AB}=\frac{1}{2}\PARENTESIS{\PROYECT{01}{10}+\PROYECT{10}{01}}$
no es el estado entrelazado $\psi_{AB}$, va a ser una mezcla estadística
de estados producto, se llama estado clásicamente correlacionado.
Es decir que cuando nosotros decimos que hay un modelo clásico que
reproduce esto, nos referimos a $\rho_{AB}\neq\PROYECT{\psi_{AB}}{\psi_{AB}}$.
Si nos restringimos a $\sigma_{z}$ nunca vamos a poder inferir que
estamos lidiando con un estado entrelazado, porque lo puedo reproducir
por un estado clásico. El estado singlete es más que $\rho_{AB}$
porque esta correlación la tiene en todas las direcciones, ese es
el punto. La diferencia entre una mezcla estadística con una cuántica
es que tiene la correlación solo en z, si por ej lo calculo en x no
la obtengo.

Volviendo al estado singlete, ahora escrito en la base de x

\[
\KET{\psi_{AB}}=\frac{\KET{+-}-\KET{-+}}{\sqrt{2}}
\]

Calculemos el valor medio

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes I_{B}}=0=\EXPECT{\psi_{AB}}{\psi_{AB}}{I_{A}\otimes\sigma_{z}^{B}}
\]

Ahora bien

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes\sigma_{x}^{B}}=-1\neq0.0
\]

La objeción del paper de EPR esta relacionada con que clásicamente
uno podría tener medias de colores (ej $\sigma_{z}$) y además indicar
su longitud (ej $\sigma_{x}$) entonces esto es una mezcla estadística
tanto de colores como de longitudes, pero cuánticamente uno no puede
tener valores simultáneos de $\sigma_{x}$ y $\sigma_{z}$ porque
son observables no conmutantes. Ahí habla de que la mecánica cuántica
esta incompleta porque sería la única forma de explicar esto que acabamos
de ver. 

El estado cuántico es igual pero el clásico

\[
\rho_{AB}=\frac{1}{2}\PARENTESIS{\PROYECT{01}{01}+\PROYECT{10}{10}}\neq\rho_{AB}'=\frac{1}{2}\PARENTESIS{\PROYECT{+-}{-+}+\PROYECT{-+}{+-}}
\]

Este es otro operador densidad. Es facil de ver esto porque la 
\[
Tr\rho_{AB}\PARENTESIS{\sigma_{z}^{A}\otimes\sigma_{z}^{B}}=-1
\]

mientras que 
\[
Tr\rho_{AB}\PARENTESIS{\sigma_{x}^{A}\otimes\sigma_{x}^{B}}=0
\]

Pero para tener correlación en x, tengo que escribir el operador $\rho_{AB}'$.
Es decir clásicamente uno puede hacer cada correlación por separado
pero no puedo hacerlo juntos.

\section{Desigualdad de Bell}

\subsection{CHSH: versión simplificada}

La idea es trasladar la discusión <<filosófica>> de EPR. Esta disigualdad
nos habla de que podemos hacer medidas que nos discriminan entre un
estado clásico y uno cuántico.

Tenemos $x$ y $z$, esto quiere decir que en un planeta medimos $x_{A}$
y $z_{A}$, tenemos una fuente que emite mil veces una partícula,
en la mitad de ellas A va a medir en $x$ y en la otra mitad en $z$.
En el lado de B mido en $x'$ y $z'$. Estas medidas son en coincidencia
es decir que en 250 de ellas A va a medir en $x$ y B en $x'$, en
otras 250 A va a medir en $x$ y B en $z'$, etc.
\begin{center}
\includegraphics{pegado12}
\par\end{center}

Ahora esto es lo que voy a medir:
\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes\sigma_{x'}^{B}}
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes\sigma_{z'}^{B}}
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{z'}^{B}}
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{x'}^{B}}
\]

¿Qué predice la mecánica cuántica de estos valores medios? Los podemos
reescribir como

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\vec{\sigma}\vec{n}_{A}\otimes\vec{\sigma}\vec{n}_{B}}=-1\vec{n}_{A}\vec{n}_{B}=-1\cos\theta
\]

Qué sería $\theta$? el ángulo que hay entre los sigmas. Calculemos
los anteriores

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes\sigma_{x'}^{B}}=-\cos\varphi
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{x}^{A}\otimes\sigma_{z'}^{B}}=-\cos\PARENTESIS{\pi/2+\varphi}=\sin\varphi
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{z'}^{B}}=-\cos\varphi
\]

\[
\EXPECT{\psi_{AB}}{\psi_{AB}}{\sigma_{z}^{A}\otimes\sigma_{x'}^{B}}=-\cos\PARENTESIS{\pi/2-\varphi}=-\sin\varphi
\]

Si nosotros consideramos ahora un observable 
\[
O_{AB}=\sigma_{x}^{A}\otimes\sigma_{x'}^{B}+\sigma_{z}^{A}\otimes\sigma_{x'}^{B}+\sigma_{z}^{A}\otimes\sigma_{z'}^{B}-\sigma_{x}^{A}\otimes\sigma_{z'}^{B}=\PARENTESIS{\sigma_{x}^{A}+\sigma_{z}^{A}}\otimes\sigma_{x'}^{B}+\PARENTESIS{\sigma_{z}^{A}-\sigma_{x}^{A}}\otimes\sigma_{z'}^{B}
\]

El valor medio de $O_{AB}$ (el valor medio de una suma es la suma
de los valores medios)

\[
\VALMEDIO{O_{AB}}=-\cos\varphi-\cos\varphi-\sin\varphi-\sin\varphi=-2\PARENTESIS{\cos\varphi+\sin\varphi}
\]

Clásicamente 

\[
O_{AB}=\LLAVEABAJO{\PARENTESIS{\sigma_{x}^{A}+\sigma_{z}^{A}}}{\underset{0}{\pm2}}\otimes\LLAVEABAJO{\sigma_{x'}^{B}}{\pm1}+\LLAVEABAJO{\PARENTESIS{\sigma_{z}^{A}-\sigma_{x}^{A}}}{\underset{\pm2}{0}}\otimes\LLAVEABAJO{\sigma_{z'}^{B}}{\pm1}
\]
es decir este observable vale siempre $\pm2$, esto implica que el
$\VALMEDIO{O_{AB}}\in\CORCHETES{-2,2}$.

Qué pasa desde el punto de vista cuántico? $-2\PARENTESIS{\cos\varphi+\sin\varphi}=-2\sqrt{2}\cos\PARENTESIS{\varphi-\frac{\pi}{4}}\in\CORCHETES{-2\sqrt{2},2\sqrt{2}}$
entonces no lo puedo reproducir con un sistema clásico. Hay valores
de $\varphi$ donde si lo puedo hacer, por eso cuando se hace el experimento
tenemos en cuenta eso. Si grafico en función de $\varphi$, y en los
lugares donde excede no hay modelos clásicos que permita reproducir
esta estadística. 
\begin{center}
\includegraphics[scale=0.5]{pegado13}
\par\end{center}

\chapter{Clase 6: 16/09}

\section{Compuertas}
\begin{center}
\begin{quantikz} \qw & \gate{U} &\qw \end{quantikz}
\par\end{center}

\subsection{Hadamard}

\[
U=e^{-iHt/\hbar}
\]

Si $\vec{B}=\vec{n}B$ y $\omega=\mu_{B}gB/2\hbar$

$H=-\vec{\mu}\vec{B}=\frac{\mu_{0}g}{2}B\vec{\sigma}\vec{n}$

$\vec{\mu}=-\mu_{B}g\frac{\vec{S}}{\hbar}=\frac{-\mu_{B}g\vec{\sigma}}{2}$

\[
U=e^{-i\omega t\vec{n}\vec{\sigma}}=\cos\PARENTESIS{\omega t}I-i\sin\PARENTESIS{\omega t}\PARENTESIS{\vec{n}\vec{\sigma}}
\]

Si $\omega t=\frac{\pi}{2}$ entonces $U=-i\vec{n}\vec{\sigma}$

\[
\vec{n}=\PARENTESIS{0,0,1}\rightarrow U=-i\sigma_{z}\alpha\PARENTESIS{\begin{array}{cc}
1 & 0\\
0 & -1
\end{array}}
\]

\[
\vec{n}=\PARENTESIS{1,0,0}\rightarrow U=-i\sigma_{x}\alpha\PARENTESIS{\begin{array}{cc}
0 & 1\\
1 & 0
\end{array}}
\]

\[
\vec{n}=\PARENTESIS{0,0,1}\rightarrow U=-i\frac{\sigma_{x}+\sigma_{z}}{\sqrt{2}}\alpha\PARENTESIS{\begin{array}{cc}
\\
\\
\end{array}}
\]


\subsection{Control not: circuito de 2 qubits}
\begin{center}
\begin{quantikz}  \qw & \ctrl{1} & \qw\\ \qw & \gate{\sigma_x}&\qw \end{quantikz}
\par\end{center}

\[
\sigma_{x}=H\sigma_{z}H
\]

con $H=H^{\dagger}$
\begin{center}
\begin{quantikz}  \qw & \ctrl{1} & \qw \\  \qw & \gate{\sigma_x}&\qw \end{quantikz}$=\KET 0\BRA 0\otimes I+\KET 1\BRA 1\otimes\sigma_{x}$
\par\end{center}

\begin{center}
\begin{quantikz}  \qw & \ctrl{1} & \qw\\ \qw & \gate{\sigma_z}&\qw \end{quantikz}$=\KET 0\BRA 0\otimes I+\KET 1\BRA 1\otimes\sigma_{z}$
\par\end{center}

$U_{cz}\KET{00}=\KET{00}$

$U_{cz}\KET{01}=\KET{01}$

$U_{cz}\KET{10}=\KET 1\sigma_{z}\KET 0=\KET{10}$

$U_{cz}\KET{11}=\KET 1\sigma_{z}\KET 1=-\KET{11}$

Uno quiere ver cuál es hamiltoniano asociado, quiero que sea diagonal
en la base del spin en z

\[
H=\alpha\sigma_{z}\otimes I+\beta I\times\sigma_{z}+\gamma\sigma_{z}\times\sigma_{z}+\delta I
\]

El control sigma z es lo mismo que de un lado que del otro, porque
es una fase, por esta simetría $\alpha=\beta=-\gamma$

$\sigma_{z}\otimes I$ es aplicar el campo magnético en alguna dirección

\[
H=\alpha\PARENTESIS{\sigma_{z}\otimes I+I\times\sigma_{z}-\sigma_{z}\times\sigma_{z}}
\]

\[
H\KET{00}=\alpha(2-1)\KET{00}=\alpha\KET{00}
\]

\[
H\KET{01}=\alpha\KET{01}
\]

\[
H\KET{10}=\alpha\KET{10}
\]

\[
H\KET{11}=-3\alpha\KET{11}
\]

\[
e^{-iHt/\hbar}=e^{-i\omega t\PARENTESIS{\begin{array}{cc}
1 & 0\\
0 & -1
\end{array}}}
\]

$\omega=\alpha/\hbar$

\[
e^{-iHt/\hbar}=e^{-i\omega t}\PARENTESIS{\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & e^{i4\omega t}
\end{array}}\ACLARACION{4\omega t=\pi/2+2\pi}=e^{-i\omega t}\PARENTESIS{\begin{array}{cccc}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & -1
\end{array}}
\]


\section{Estados no puros}

Para 1 qubit, un estado no puro tiene la forma general 
\[
\rho=p\PROYECT{0'}{0'}+\PARENTESIS{1-p}\PROYECT{1'}{1'}=\frac{1}{2}\PARENTESIS{I+\vec{r}\vec{\sigma}}
\]
con $\vec{r}=\VALMEDIO{\vec{\sigma}}$ y $\vec{S}=\frac{\vec{\sigma}}{2}\hbar$,
$dim\HILBERT=2$

\subsection{Ejemplo de tomografía de estados cuánticos.}

Se requiere conocer $\VALMEDIO{\vec{\sigma}}$ para determinar la
medida, es decir necesito los valores medios en cada dirección.

El número de medidas necesarias en un $\HILBERT$ es $d^{2}-1$

Caso puro $\rho^{2}=\rho$ luego $\vec{r}\vec{r}=1$

Caso no puro $\rho^{2}\leq\rho$, luego $\vec{r}\vec{r}<1$

Caso máximamente mezclado $\vec{r}\vec{r}=0\rightarrow\vec{r}=\vec{0}$

Si $\rho=\rho^{\dagger}$, $Tr\rho=1$ y $\rho\in\COMPLEJOS^{d\times d}$
entonces $d+\frac{d(d-1)}{2}2-1=d+d(d-1)-1=d^{2}-1$

Si tendo n qubits: $d=2^{n}$

2 quibits: son 15 medidas.

\subsection{Cómo los generamos}

1) Si tenemos una fuente que emite $\KET{0'}$ con prob $p$ y $\KET{1'}$
con prob 1-p, $\rho=p\PROYECT{0'}{0'}+\PARENTESIS{1-p}\PROYECT{1'}{1'}$,
esto es algo <<clásico>>

2) FIG 3

$\rho_{A}=Tr_{B}\PROYECT{\psi_{AB}}{\psi_{AB}}=Tr_{B}\PARENTESIS{\alpha\KET{00}+\beta\KET{11}}\PARENTESIS{\alpha^{*}\BRA{00}+\beta^{*}\BRA{11}}=\LLAVEABAJO{\MODULO{\alpha}^{2}}p\PROYECT 00+\LLAVEABAJO{\MODULO{\beta}^{2}}{p-1}\KET 1\BRA 1$

Entonces en A obtuve en un estado mezcla en forma <<cuántica>>

\subsection{Estados no puros de 2 qubits}

La idea es escribirlo por una base que sea el producto tensorial de
las bases: $\LLAVES{I,\sigma_{x},\sigma_{y},\sigma_{z}}\otimes\LLAVES{I,\sigma_{x},\sigma_{y},\sigma_{z}}$
Vamos a tener 16 elementos que son ortogonales. Tenemos 9 medidas
$\sigma_{\nu}\otimes\sigma_{\mu}$ en coincidencia y 3 de cada 1 por
separado, ie 15 medidas en total.

$\rho_{AB}=\frac{1}{4}\PARENTESIS{I+\vec{r}_{A}\vec{\sigma}\otimes I+I\otimes\vec{r}_{B}\vec{\sigma}+\sum_{i,j=1}^{3}r_{ij}\sigma_{i}\otimes\sigma_{j}}$

Puse el $1/4$ porque $Tr\rho_{AB}=1$ y la de $TrI=4$ y la $Tr(\sigma_{\nu}\otimes\sigma_{\mu})=0$
con $\nu,\mu=0,1,2,3$

\[
Tr\rho_{AB}\PARENTESIS{\vec{\sigma}\otimes I}=\vec{r}_{A}=\VALMEDIO{\vec{\sigma_{A}}}
\]

\[
Tr\rho_{AB}\PARENTESIS{I\otimes\vec{\sigma}}=\vec{r}_{B}=\VALMEDIO{\vec{\sigma_{B}}}
\]

\[
r_{ij}=Tr\rho_{AB}\PARENTESIS{\sigma_{i}\otimes\sigma_{j}}=\VALMEDIO{\sigma_{i}\otimes\sigma_{j}}
\]

Estas 15 medidas hacen la tomografía de 2 qubits.

\subsection{Entrelazamiento de estados no puros}

La definición que vimos para estados puros es:

\[
\KET{\psi_{AB}}=\KET{\psi_{A}}\KET{\psi_{B}}\rightarrow\KET{\psi_{AB}}\text{ estado separable o producto}
\]

\[
\KET{\psi_{AB}}\neq\KET{\psi_{A}}\KET{\psi_{B}}\rightarrow\KET{\psi_{AB}}\text{ estado entrelazado}
\]

Para estados no puros:

Lo que es gratis productir en el laboratorio o bien son estados productos
o de este tipo:

\[
\rho=p\PROYECT{\uparrow\uparrow}{\uparrow\uparrow}+\PARENTESIS{1-p}\KET +\KET +\BRA +\BRA +=p\PROYECT{\uparrow}{\uparrow}\otimes\PROYECT{\uparrow}{\uparrow}+\PARENTESIS{1-p}\KET +\BRA +\otimes\KET +\BRA +
\]

Si uno diagonaliza el estado este va a ser entrelazado. 

\subsubsection{Estados separables no puro}

Estados que pueden generarse por LOCC (local operation of clasical
comunication), local operation: me quedo con el spin para arriba pongo
un Stern y gerlach y me quedo con esa dirección, clasical comunication:
llamo y le digo el estado que genero para que mande el mismo. 

\[
\rho_{AB}=\sum_{i}p_{i}\PROYECT{i_{A}}{i_{A}}\otimes\PROYECT{i_{B}}{i_{B}}
\]
 corresponde a una mezcla estadística de estados producto (si fuera
una mezcla coherente es un estado entrelazado), se llama \textbf{combinación
convexa de estado producto, }se dice convexa porque los $p_{i}\geq0$.
Son fáciles de generar en el lab.

Ahora 
\[
\rho_{AB}\neq\sum_{i}p_{i}\PROYECT{i_{A}}{i_{A}}\otimes\PROYECT{i_{B}}{i_{B}}
\]

Se dice \textbf{entrelazado}. 

Volvamos a esos estados separables no puros, los puedo reescribir
como

\[
\rho_{AB}=\sum_{i}p_{i}\PROYECT{i_{A}i_{B}}{i_{A}i_{B}}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}
\]
con $p_{\alpha}\geq0$ y $\sum_{\alpha}p_{\alpha}=1$

Los estados productos son un caso particular de estados separables.

\subsection{¿Cómo sabemos si este estado no puro es entrelazado o separable?}

Dicho de otra forma
\[
\rho_{AB}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}
\]
con $p_{\alpha}\geq0$ y $\sum_{\alpha}p_{\alpha}=1$.

\subsubsection{Criterio de Peres (PPT)}

PPT: transpuesta parcial.

Si $\rho_{AB}$ es separable entonces $\rho_{AB}^{T_{B}}\geq0$, con
$\lambda\PARENTESIS{\rho_{AB}}\geq0$.

Qué quiere decir esto?

Si tenemos $\PROYECT{ij}{kl}=\PROYECT ik\otimes\PROYECT jl$ entonces
\[
\PARENTESIS{\PROYECT{ij}{kl}}^{T_{B}}=\PROYECT{il}{kj}=\PROYECT ik\otimes\PROYECT lj
\]

Si $\rho_{AB}$ es separable entonces 
\[
\rho_{AB}^{T_{B}}=\sum_{\alpha}p_{\alpha}\PARENTESIS{\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}}^{T_{B}}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\PARENTESIS{\rho_{B}^{\alpha}}^{T}
\]

La traspuesta de $\rho_{B}^{\alpha}$ no cambia los autovalores, entonces
la traza sigue siendo 1. $\PARENTESIS{\rho_{B}^{\alpha}}^{T}=\rho_{B}^{\alpha}$,
$\PARENTESIS{\PARENTESIS{\rho_{B}^{\alpha}}^{T}}^{T}=\PARENTESIS{\rho_{B}^{\alpha}}^{T}$,
$Tr\PARENTESIS{\rho_{B}^{\alpha}}{}^{T}=Tr\rho_{B}^{\alpha}$

Ej: 
\[
\KET{\psi_{AB}}=\frac{\KET{00}+\KET{11}}{\sqrt{2}}
\]

\[
\rho_{AB}=\PROYECT{\psi_{AB}}{\psi_{AB}}=\frac{1}{2}\PARENTESIS{\LLAVEABAJO{\overset{}{\overset{\KET 0\BRA 0\otimes\KET 0\BRA 0}{\PROYECT{00}{00}}+\overset{\KET 1\BRA 1\otimes\KET 1\BRA 1}{\PROYECT{11}{11}}}}{\text{esto es separable }}+\PROYECT{00}{11}+\PROYECT{11}{00}}
\]

\[
\rho_{AB}^{T_{B}}=\frac{1}{2}\PARENTESIS{\PROYECT{00}{00}+\PROYECT{11}{11}+\PROYECT{01}{10}+\PROYECT{10}{01}}
\]

vemos arriba como era $\rho_{AB}$ sin transponer y vemos como afecta.
Los autovalores son

\[
\lambda\PARENTESIS{\rho_{AB}^{T_{B}}}=\PARENTESIS{\frac{1}{2}+\frac{1}{2}+\frac{1}{2}-\frac{1}{2}}
\]
cuando aplicamos la traza parcial a un estado entrelazado obtenemos
un autovalor negativo, entonces aplicar la traza parcial me genera
un $\rho_{AB}^{T_{B}}$ no es un operador densidad.

\paragraph{Resumen: Criterio PPT: me dice que si $\rho_{AB}$ es separable entonces
$\rho A_{B}^{T_{B}}\protect\geq0$ entonces $\lambda\protect\PARENTESIS{\rho_{AB}^{T_{B}}}\protect\geq0$
(es decir sigue siendo un operador densidad). El contra-recíproco sería
que $\rho A_{B}^{T_{B}}\cancel{\protect\geq}0$ es decir $\exists\lambda_{i}\protect\PARENTESIS{\rho_{AB}^{T_{B}}}<0$,
entonces $\rho_{AB}$ es entrelazado.}

Es un criterio necesario de separabilidad pero no suficiente de separable.

Excepción sistema de 2 qubits, en el sentido que el criterio de PPT
es necesario y suficiente. 

\subsection{Medida de negatividad}

\[
N(\rho_{AB})=-\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}=\frac{Tr\MODULO{\rho_{AB}^{T_{B}}}-1}{2}
\]

Dem: 
\[
Tr\MODULO{\rho_{AB}^{T_{B}}}=\RED{\sum_{\lambda_{i}>0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}}-\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}+\RED{\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}}-\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}
\]

\[
=\RED{\LLAVEABAJO{Tr\rho_{AB}^{T_{B}}}{=1}}-2\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho_{AB}^{T_{B}}}=1+2N\quad\blacksquare
\]


\subsection{Ejemplo típico del lab}

Sistema de 2 qubits

\[
\rho_{AB}=p\PROYECT{\psi_{AB}}{\psi_{AB}}+\PARENTESIS{1-p}\frac{I_{AB}}{4}
\]

$\frac{I_{AB}}{4}$ este es el estado máximamente mezclado.

\textbf{¿Cuál es el valor umbral de p para que exista entrelazamiento?}

\[
\rho_{AB}=\left(\begin{array}{cccc}
\frac{p}{2}+\frac{1-p}{4} & 0 & 0 & \frac{p}{2}\\
0 & \frac{1-p}{4} & 0 & 0\\
0 & 0 & \frac{1-p}{4} & 0\\
\frac{p}{2} & 0 & 0 & \frac{1-p}{4}
\end{array}\right)
\]

Si hacemos la transpuesta parcial, 
\[
\rho_{AB}^{T_{B}}=\left(\begin{array}{cccc}
\frac{p}{2}+\frac{1-p}{4} & 0 & 0 & 0\\
0 & \frac{1-p}{4} & \frac{p}{2} & 0\\
0 & \frac{p}{2} & \frac{1-p}{4} & 0\\
0 & 0 & 0 & \frac{1-p}{4}
\end{array}\right)
\]

\[
\lambda\PARENTESIS{\rho_{AB}^{T_{B}}}=\PARENTESIS{\frac{p}{2}+\frac{1-p}{4},\frac{p}{2}+\frac{1-p}{4},\frac{p}{2}\pm\frac{1-p}{4}}
\]

\[
\frac{1-p}{4}-\frac{p}{2}<0\rightarrow1-3p<0\rightarrow p>\frac{1}{3}
\]


\chapter{Clase 7: 18/09}

Un estado mezcla de esta forma
\[
\rho_{AB}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}
\]
decimos que es una combinación convexa de estados producto. Con $p_{\alpha}\geq0$,
$\sum_{\alpha}p_{\alpha}=1$. Además si $\rho_{AB}$ es de esta forma
es \textbf{separable} (en caso contrario es entrelazado) y entonces
puede ser generado por LOCC (operaciones locales y comunicación clásica).
Uno podría llegar a expandir a este operador densidad $\rho_{AB}$
en una base de producto de operadores, pero estos $p_{\alpha}$ no
van a ser todos positivos. Un estado que sea general entrelazado no
va a cumplirlo.

\subsection{Criterios necesarios de separabilidad}

\subsubsection{Traspuesta parcial}

$\rho_{AB}$ es separable entonces $\rho^{T_{A}}\ge0$ que es equivalente
a decir que $\lambda\PARENTESIS{\rho^{T_{A}}}\ge0$

Recordar que $\lambda\PARENTESIS{\rho^{T_{A}}}=\lambda\PARENTESIS{\rho^{T_{B}}}$,
$\PARENTESIS{\rho^{T_{A}}}^{\dagger}=\rho^{T_{A}}$.

\subsubsection{Negatividad}

\[
N=-\sum_{\lambda_{i}<0}\lambda_{i}\PARENTESIS{\rho^{T_{A}}}=\frac{Tr\MODULO{\rho}-1}{2}
\]

Este criterio es suficiente para un sistema de 2 qubits.

Para estados puros (generales) es \textbf{necesario y suficiente}
en todo sistema:

Si tenemos un estado puro bipartito lo puedo escribir en la descomposición
de Schmidt

\[
\KET{\psi_{AB}}=\sum_{k=1}^{n_{s}}\sigma_{k}\KET{k_{A}}\KET{k_{B}}
\]
 a partir de acá construyo un operador $\rho_{AB}=\PROYECT{\psi_{AB}}{\psi_{AB}}$
y se puede ver que 
\[
N=\sum_{k<k'}\sigma_{k}\sigma_{k'}=\frac{\PARENTESIS{\sum_{k}\sigma_{k}}^{2}-1}{2}
\]
 si $n_{s}=1$ entonces no hay ninguno menor a otro entonces es 0,
de acá se puede ver entonces que si $n_{s}=2$, $N\neq0$.

Si escribimos el $\rho_{AB}=\PROYECT{\psi_{AB}}{\psi_{AB}}$ en la
descomposición de Schmidt

\[
\rho_{AB}=\sum_{k,k'}\sigma_{k}\KET{k_{A}}\KET{\ORANGE{k_{B}}}\sigma_{k'}\BRA{k'_{A}}\BRA{\ORANGE{k'_{B}}}
\]

Le hago la traspuesta parcial que me va a cambiar lo que marque en
naranja entre si:

\[
\rho_{AB}^{T_{B}}=\sum_{k,k'}\sigma_{k}\sigma_{k'}\KET{k_{A}}\KET{k'_{B}}\BRA{k'_{A}}\BRA{k_{B}}
\]

\[
=\LLAVEABAJO{\sum_{k}\sigma_{k}^{2}\KET{k_{A}k_{B}}\BRA{k_{A}k_{B}}}{\text{elem diag}}+\LLAVEABAJO{\sum_{k\neq k'}\sigma_{k}\sigma_{k'}\KET{k_{A}}\KET{k'_{B}}\BRA{k'_{A}}\BRA{k_{B}}}{\text{bloque fuera de la diag que me da autoval neg}}
\]

Emerge un autovalor negativo por cada bloque $kk'$. Estamos en qutris
d=3
\[
\begin{array}{cc}
 & \begin{array}{ccccccccc}
00 & 01 & 02 & 10 & 11 & 12 & 20 & 21 & 22\end{array}\\
=\begin{array}{c}
00\\
01\\
02\\
10\\
11\\
12\\
20\\
21\\
22
\end{array} & \left(\begin{array}{ccccccccc}
\sigma_{0}^{2} &  &  &  & \text{ } & \text{ } & \text{ } & \text{ } & \text{ }\\
 & \RED 0 &  & \RED{\sigma_{0}\sigma_{1}}\\
 &  &  &  & \text{ }\\
 & \RED{\sigma_{0}\sigma_{1}} &  & \RED 0\\
 &  &  &  &  &  & \text{ }\\
 &  &  &  &  &  &  & \text{ }\\
 &  &  &  &  &  &  &  & \text{ }\\
 &  &  &  &  &  &  & \text{ }\\
 &  &  &  &  &  & \text{ }
\end{array}\right)
\end{array}
\]

Se arma un bloque aislado que es $\PARENTESIS{\begin{array}{cc}
0 & \sigma_{0}\sigma_{1}\\
\sigma_{0}\sigma_{1} & 0
\end{array}}$, entonces puedo obtener los autovalores diagonalizando esta matriz
de 2x2, tiene autovalores son $\pm\sigma_{0}\sigma_{1}$, aparece
el menos automáticamente.

Entonces vemos que la negatividad total es $N=\sum_{k<k'}\sigma_{k}\sigma_{k'}$

\subsubsection{Criterio de desorden (o entrópico) de separabilidad}

$\rho_{AB}$ separable $\Rightarrow$ $S(A,B)\geq S(A)$ y $S(A,B)\geq S(B)$.

Es necesario pero no suficiente.

\subsection{Testigo de entrelazamiento}

Un testigo de entrelazamiento es un operador autoadjunto $O_{AB}$
tal que $Tr\rho_{AB\,sep}O_{AB}\geq0$ $\forall\rho_{AB\:sep}$. Pero,
dado un cierto $\rho_{AB}^{E}$ entrelazado $Tr\rho_{AB}^{E}O_{AB}<0$
(esto vale solo para un cierto $\rho_{AB}^{E}$ no para todos).

\paragraph{Dado $\rho_{AB}$ entrelazado $\exists$ $O_{AB}$ tal que $Tr\rho_{AB}O_{AB}<0$,
pero la traza de cualquier operador separable $Tr\rho_{AB}^{S}O_{AB}\protect\geq0$
$\forall\rho_{AB}^{S}$. }


\subsubsection{Demostración}
\begin{center}
\includegraphics[scale=0.5]{\string"fig clase 1809\string".pdf}
\par\end{center}

\textbf{1) }El conjunto de todos los $\rho$ de un sistema físico
es un conjunto convexo. Quiere decir que si $\rho_{1}$ es operador
densidad y $\rho_{2}$ es operador densidad entonces $p\rho_{1}+(1-p)\rho_{2}$
es un operador densidad $\forall p\in\CORCHETES{0,1}$. 

Entonces si supongamos que este es el conjunto de los operadores densidad
y el borde de los $\rho$ son los estados puros. Todo conjunto convexo
se pueden generar a partir de unos estados borde, estados límite.
Porque del punto de vista matemático un punto que está en el medio
entre dos estados de borde lo puedo escribir como combinación lineal
de dos estados de borde de la forma $p\rho_{1}+(1-p)\rho_{2}$.

Dentro del conjunto convexo de todos los operadores densidad de un
sistema dado. En el borde estados puros. Adentro está el conjunto
de los $\rho$ separables.

\textbf{2) }El conjunto de los operadores densidad separables para
un dado sistema físico es convexo. La robustez de un operador separable
que mezclas cosas y seguís estando ahí adentro no la tienen los operadores
producto, una mezcla de producto no es un operador producto. Por eso
el concepto de separabilidad es importante.

\[
\begin{array}{c}
\rho_{1}=\sum_{\alpha}p_{\alpha}^{1}\rho_{A}^{1\alpha}\otimes\rho_{B}^{1\alpha}\\
\rho_{2}=\sum_{\alpha}p_{\alpha}^{2}\rho_{A}^{2\alpha}\otimes\rho_{B}^{2\alpha}
\end{array}\Rightarrow q\rho_{1}+(1-q)\rho_{2}=\sum_{\alpha}qp_{\alpha}^{1}\rho_{A}^{1\alpha}\otimes\rho_{B}^{1\alpha}+(1-q)p_{\alpha}^{2}\rho_{A}^{2\alpha}\otimes\rho_{B}^{2\alpha}
\]

Esto sigue siendo un operador densidad separable, mientras $q\in\CORCHETES{0,1}$. 

\paragraph{Desde el punto de vista físico la propiedad de convexidad es importante
porque te esta diciendo que si yo genero algo en este conjunto y hago
mezclas de eso, es decir que por ej. si tiro un dado cuando en el
dado sale 1 genero un cierto estado separable, cuando me sale 2 otro,
y así, y el estado promedio que sale es un estado separable también.
Es decir mezclando esas cosas no me voy del conjunto. \\}

El conjunto de estados producto no es convexo, porque no son conmutantes.
Los estados separables tienen en general autoestados entrelazados,
el hecho que sea una combinación convexa de productos como estos
estados $\PARENTESIS{\rho_{AB}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}}$
que estamos sumando, donde cada $\alpha$ es un índice de estado $\rho_{A}$,
$\rho_{B}$ cualquiera donde no tienen porque ser conmutantes, son
suma de productos no conmutantes. Al sumar todo esto al ser no conmutantes,
si uno analiza esto, no todos o una buena parte son entrelazados.
Pero aún así el estado separable es generable por operaciones locales
y comunicación clásica LOCC. 

Notar que el conjunto de los operadores densidad $\rho$ se toca en
sólo punto con el de los $\rho_{s}$, es un punto donde es separable
y puro al mismo tiempo y es uno sólo porque \textbf{implica} que $\rho$
es un producto
\[
\rho=\KET{k_{A}}\KET{k_{A}}\otimes\BRA{k_{B}}\BRA{k_{B}}\rightarrow\rho=\KET{\psi_{AB}}\BRA{\psi_{AB}}
\]

Volvamos a la \textbf{demostración}, supongamos que tenemos un $\rho_{AB}$
entrelazado, y tenemos la recta roja que me divide el espacio en 2
semiplanos (sup que estamos en 2 d)
\begin{center}
\includegraphics[scale=0.5]{\string"fig clase 1809- 2\string".pdf}
\par\end{center}

Esto pasa a $\GREEN{Tr\rho_{AB}O_{AB}\geq0}$ y a $\BLUE{Tr\rho_{AB}O_{AB}\geq0}$,
siendo los coeficientes $a,\:b,\:c$ sería el operador testigo $O_{AB}$
y las coordenadas $x,\:y$ son los elementos del operador $\rho_{AB}$
en una base de operadores y esta condición sobre $Tr\rho_{AB}O_{AB}$
es una proyección lineal de $\rho_{AB}$ sobre alguna base. El hecho
que $\rho^{s}$ sea convexo hace que exista una recta entre $\rho$
entrelazado y $\rho^{s}$, entonces se prende la <<lamparita>> cuando
estoy de uno de los lados.$\blacksquare$

Podemos ver que el entrelazamiento es muy débil porque ponele que
genero un estado que este del lado izquierdo que caiga fuera del conjunto
de los separables, eso no es un conjunto convexo entonces me va a
fallar. Es decir, en cuanto tenga probabilidad de generar un entrelazado
ahí se cae el entrelazamiento, y eso puede pasar si hay ruido. En
cambio con los separables no pasa eso.

\paragraph{El conjunto de estados entrelazados no es convexo.}

\subsubsection{Ejemplo}

Supongamos que tenemos los estados de Bell

\[
\left\{ \begin{array}{c}
\KET{\psi_{\underset{01}{00}}}=\frac{\KET{00}\pm\KET{11}}{\sqrt{2}}\\
\KET{\psi_{\underset{11}{10}}}=\frac{\KET{01}\pm\KET{10}}{\sqrt{2}}
\end{array}\right\} \text{base de estados de 2 qubits de }\COMPLEJOS^{2}\otimes\COMPLEJOS^{2}
\]

\begin{center}
\begin{quantikz}  \lstick{$\ket{i}$} & \gate{H} & \ctrl{1} & \midstick[2,brackets=none]{$\ket{\psi_{ij}}$}\qw\\  \lstick{$\ket{j}$} & \qw & \octrl{-1} & \qw \end{quantikz} 
\par\end{center}

Tenemos que el estado $\PROYECT{\psi_{ij}}{\psi_{ij}}$ es entrelazado
pero 
\[
\sum_{i,j=0}^{1}\PROYECT{\psi_{ij}}{\psi_{ij}}\frac{1}{4}=\frac{I_{AB}}{4}\text{ es el estado máximamente mezclado}
\]
Como la identidad es la identidad en todas las bases, entonces lo
anterior es igual a 

\[
=\frac{1}{4}\sum_{i,j=0}^{1}\KET i\KET j\BRA i\BRA j=\frac{1}{4}\PARENTESIS{\KET{00}\BRA{00}+\KET{01}\BRA{01}+\KET{10}\BRA{10}+\KET{11}\BRA{11}}
\]
genero un ruido al azar. Esto implica que las medidas de entrelazamiento
no son cóncavas sino son convexas ie el entrelazamiento de una mezcla
tiene que ser menor que la mezcla de entrelazamientos. El entrelazamiento
de un promedio siempre es menor o igual que el promedio de los entrelazamientos. 

\subsection{¿Cómo mido el valor medio de entrelazamiento de estados no puros?}

Miremos primero como calculo el valor medio de la energía

\[
\VALMEDIO H=Tr\rho H
\]
con $H$ un hamiltoniano, con $\rho=\sum_{i}p_{i}\PROYECT ii$, luego
$\VALMEDIO H=\sum_{i}p_{i}\EXPECT iiH=\sum_{i}\VALMEDIO H_{i}p_{i}$
implica un valor medio cuántico con distribución de probabilidad y
un valor medio clásico con $p_{i}$.

Nosotros sabemos que el entrelazamiento de un estado puro $E\PARENTESIS{\KET{\psi_{AB}}}=S\PARENTESIS{\rho_{A}}=S\PARENTESIS{\rho_{B}}$,
con $\rho_{A}=Tr_{B}\PROYECT{\psi_{AB}}{\psi_{AB}}$, entonces uno
podría decir $\PARENTESIS{\RED{\text{ESTO ESTÁ MAL!!! - ES UN PPIO}}}$
que uno puede definir $E\PARENTESIS{\rho_{AB}}=\sum_{i}p_{i}E\PARENTESIS{\KET{\psi_{AB}}}$,
esta definición no tiene sentido por el ej que vimos recién de estados
de Bell, si aplico esta definición de entrelazamiento a la expresión
a una mezcla de estados de Bell me da 1 y si lo aplico a una mezcla
de estados producto me da 0, es decir me queda $0=1$. Tiene que ser
una propiedad del vector pero no debe depender de la representación
que elija al vector. 

\subsubsection{Entrelazamiento de formación}

\[
E\PARENTESIS{\rho_{AB}}=\underset{\LLAVES{p_{i}\KET{\psi_{AB}^{i}}/\sum_{i}p_{i}\PROYECT{\psi_{AB}^{i}}{\psi_{AB}^{i}}=\rho_{AB}}}{\text{Min}}\sum_{i}p_{i}E\PARENTESIS{\KET{\psi_{AB}^{i}}}
\]
 Tomo el mínimo sobre todas las representaciones. Esto es consistente
ya que cumple que $E\PARENTESIS{\rho_{AB}}\ge0$, $E\PARENTESIS{\rho_{AB}}=0\iff\rho_{AB}\text{ separable}$. 

Este no es un criterio necesario y suficiente porque está muy bien
pero no es computable (no es física, porque tenés que pensar sobre
todas las posibles mezclas que te da un estado, es un espacio infinito). 

\textbf{Caso de 2 qubits. Wooters}

Logró evaluar de forma analítica $E\PARENTESIS{\rho_{AB}}$ $\forall\rho_{AB}$
de 2 qubits.

\subsubsection{Fórmula de Wooters (2 qubits) }

\[
E\PARENTESIS{\rho_{AB}}=-\sum_{i=0,1}p_{i}\log p_{i}=S\PARENTESIS{\rho_{A}}=S\PARENTESIS{\rho_{B}}
\]

Donde $p_{\overset{0}{1}}=\frac{1\pm\sqrt{1-c^{2}}}{2}$, con $c$
la concurrencia. Siendo $c=2\lambda_{max}(R)-Tr(R)$ y $R=\sqrt{\rho_{AB}^{1/2}\tilde{\rho}_{AB}\rho_{AB}^{1/2}}$,
con $\tilde{\rho}_{AB}=\sigma_{y}\otimes\sigma_{y}\rho_{AB}^{*}\sigma_{y}\otimes\sigma_{y}$. 

Para \textbf{estados puros} $E\PARENTESIS{\rho_{AB}}=S\PARENTESIS{\rho_{A}}=S\PARENTESIS{\rho_{B}}$.
Para estados mezcla $S\PARENTESIS{\rho_{A}}\neq S\PARENTESIS{\rho_{B}}$
y no mide ni entrelazamiento ni correlación. 

Para estados puros la concurrencia la podemos calcular como $c\PARENTESIS{\rho_{AB}}=\sqrt{1-Tr\PARENTESIS{\rho_{AB}^{2}}}$,
es decir todas las medidas de correlación o entrelazamiento bien definidas
cuando son medidas para un estado puro deben reducirse a una medida
de entropía de estado local (no necesariamente la de Shannon). La
$Tr\PARENTESIS{\rho_{AB}^{2}}$ se llama pureza, ya que da 1 para
estados puros ya que $\rho_{AB}^{2}=\rho_{AB}$.

\subsection{Algoritmos para estados mezcla - Knill & LaFlamme - intro}

\begin{quantikz}  \lstick{$\ket{0}$} & \gate{H} & \qw & \ctrl{1} & \qw   & \rstick{$\begin{matrix} \langle \sigma_x \rangle=Re(Tr U)\\ \langle \sigma_y \rangle=Im(Tr U) \end{matrix}$} \qw  \\ \lstick{$\frac{I_{2^n}}{(\sqrt{2})^n}$} &\qwbundle[alternate]{}&\qwbundle[alternate]{}&\gate{U}\qwbundle[alternate]{} & \qwbundle[alternate]{}  \end{quantikz} 

Tenemos este circuito, entra un estado $\frac{I_{2^{n}}}{(\sqrt{2})^{n}}$
cualquiera que puede ser mezcla. A la salida mido $\VALMEDIO{\sigma_{x}}$,
$\VALMEDIO{\sigma_{y}}$ esto te da la $Re\PARENTESIS{TrU}$ y la
$Im\PARENTESIS{TrU}$, respectivamente. Esto nos permitiría evaluar
directamente la $TrU$ sin mucha dificultad, lo cual para un sistema
de $n$ qubits es difícil. 

\[
\rho_{AB}\begin{cases}
\begin{array}{c}
\rho_{sep}\begin{cases}
\begin{array}{c}
\text{producto }\rho_{A}\otimes\rho_{B}\\
\text{clásicamente correlacionados }\rho_{AB}=\sum_{ij}p_{ij}\PROYECT{ij}{ij}\\
\rho_{AB}=\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}
\end{array} & \begin{array}{c}
\\
\text{1eros 2: clásicos}\\
\text{caso intermedio}
\end{array}\end{cases}\\
\begin{array}{cc}
\text{no separables o entrelazados} & \text{caso cuántico}\end{array}
\end{array}\end{cases}
\]


\chapter{Clase 8: 25/09}

\section{Algoritmos para estados mezcla - Knill & LaFlamme 1998 (\textit{Deterministic
quantum computation with one qubit - DQC1)}}

Las razones por las cuales por las que los estados mezclas se volvieron
importantes es por su aplicación en los algoritmos de Knill & LaFlamme,
porque se puede hacer computación cuántica con estados mezcla, con
mucho ruido y a temperatura ambiente. 

\begin{quantikz}  \lstick{$\ket{0}$} & \gate{H} & \qw &  \ctrl{1} & \qw   &\meter {}  \\ &\lstick{$\frac{I_{2^n}}{(\sqrt{2})^n}$} &\qwbundle[alternate]{}&\gate{U}\qwbundle[alternate]{} & \qwbundle[alternate]{}  \end{quantikz} 

En el canal 1 luego de la Hadamard tenemos el estado $\KET +=\frac{\KET 0+\KET 1}{\sqrt{2}}$
y en los otros antes de la compuerta U tenemos el estado $\KET{\psi}$

$\PARENTESIS{\frac{\KET 0+\KET 1}{\sqrt{2}}}\otimes\KET{\psi}\rightarrow\LLAVEABAJO{\PARENTESIS{\KET 0\KET{\psi}+\KET 1U\KET{\psi}}}{\KET{\psi_{AB}}}\frac{1}{\sqrt{2}}$

Luego 
\[
\rho_{A}=Tr_{B}\PROYECT{\psi_{AB}}{\psi_{AB}}Tr_{B}\frac{1}{2}\PARENTESIS{\PROYECT 00\otimes\PROYECT{\psi}{\psi}+\PROYECT 11\otimes U\PROYECT{\psi}{\psi}U^{\dagger}+\PROYECT 01\otimes\PROYECT{\psi}{\psi}U^{\dagger}+\PROYECT 10\otimes U\PROYECT{\psi}{\psi}}
\]

\[
=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PROYECT 01\LLAVEARRIBA{\EXPECT{\psi}{\psi}{U^{\dagger}}}{\psi\text{ es base de }U}+\PROYECT 10\EXPECT{\psi}{\psi}U}
\]

Si ahora hago 
\[
\VALMEDIO{\sigma_{x}^{A}}=Tr\PARENTESIS{\rho_{A}\sigma_{x}}=\EXPECT{\psi}{\psi}{U^{\dagger}}+\EXPECT{\psi}{\psi}U=2Re\EXPECT{\psi}{\psi}U
\]

\[
\VALMEDIO{\sigma_{y}^{A}}=Tr\PARENTESIS{\rho_{A}\sigma_{y}}=\EXPECT{\psi}{\psi}U/i-\EXPECT{\psi}{\psi}{U^{\dagger}}/i=2Im\EXPECT{\psi}{\psi}U
\]

Ahora cuando aplico esto a una mezcla estadística de estados, a la
salida tengo una mezcla estadística de estados.

La idea ahora es poner un $\rho=\sum_{i}p_{i}\PROYECT{\psi_{i}}{\psi_{i}}$,
lo que vamos a obtener de todo esto, como es lineal, el resultado
va a ser la mezcla estadística de todo.

\[
\rho_{iA}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PROYECT 01\EXPECT{\psi}{\psi}{U^{\dagger}}+\PROYECT 10\EXPECT{\psi}{\psi}U}
\]

\[
\rho_{A}=\sum_{i}p_{i}\rho_{iA}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PROYECT 01\sum_{i}p_{i}\VALMEDIO{U^{\dagger}}_{i}+\PROYECT 10\sum_{i}p_{i}\VALMEDIO U_{i}}
\]

Si ahora $\rho_{B}^{0}=\frac{1}{2^{n}}\sum_{i}\PROYECT{\psi_{i}}{\psi_{i}}=\frac{1}{2^{n}}I_{B}$,
es decis mandamos un estado completamente mezclado, temperatura infinita
(cra la dif de energía entre niveles, temp ambiente)

Entonces, ahora como los $p_{i}$ son todos iguales 
\[
\rho_{A}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PROYECT 01\sum_{i=1}^{2^{n}}\frac{\EXPECT ii{U^{\dagger}}}{2^{n}}+\PROYECT 10\sum_{i=1}^{2^{n}}\frac{\EXPECT iiU}{2^{n}}}
\]

\[
\rho_{A}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PROYECT 01\PARENTESIS{\frac{TrU}{2^{n}}}^{*}+\PROYECT 10\PARENTESIS{\frac{TrU}{2^{n}}}}
\]

Ahora estoy facilitándome la cuenta de la $TrU$, cuando $U$ es muy
grande. Solo necesito hacer muchas veces (ej 100) el circuito para
obtener el $\VALMEDIO{\sigma_{x}}$, $\VALMEDIO{\sigma_{y}}$. Volvemos
a obtener que 

\[
\VALMEDIO{\sigma_{x}}=Tr\PARENTESIS{\rho_{A}\sigma_{x}}=2ReTr\PARENTESIS U/2^{n}
\]

\[
\VALMEDIO{\sigma_{y}}=Tr\PARENTESIS{\rho_{A}\sigma_{y}}=2ImTr\PARENTESIS U/2^{n}
\]

Entonces cuando meto 
\[
\frac{I_{B}}{2^{n}}\rightarrow U\frac{I_{B}}{2^{n}}U^{\dagger}=\frac{I_{B}}{2^{n}}\qquad UU^{\dagger}=I_{B}
\]
uno medio naive piensa que no sirve para nada, pero en realidad la
importancia está en los términos cruzados. 

En esto tenemos entrelazamiento, o tenemos muy poco, entonces este
estado es tipo separable y pensaban que esto es simulable clásicamente,
pero no es así, por lo que esta diciendo que los estados mezcla tiene
algunas propiedades que no tienen los estados clásicos. El recurso
que está atrás se llama \emph{discord} que no está terminado de estudiar. 

Este algoritmo inauguró lo que se llama mixed state q.c, lo tradicional
es pure state q.c.

\subsection{¿Qué pasa si el qubit de control en vez de ser puro es mezcla?}

Veamos primero que sucede si pongo a la entrada un $\KET 1\overset{H}{\rightarrow}\frac{\KET 0-\KET 1}{\sqrt{2}}$,
lo que va a quedar si hacemos toda la cuenta es que el

\[
\rho_{A}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11-\PROYECT 01\PARENTESIS{\frac{TrU}{2^{n}}}^{*}-\PROYECT 10\PARENTESIS{\frac{TrU}{2^{n}}}}
\]

\[
\VALMEDIO{\sigma_{x}}=Tr\PARENTESIS{\rho_{A}\sigma_{x}}=-Re\EXPECT{\psi}{\psi}U
\]

Ahora sup que entramos con una mezcla $p\PROYECT 00+q\PROYECT 11$,
con $q=1-p$

\includegraphics{pegado31}

\[
\rho_{A}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11+\PARENTESIS{p-q}\PROYECT 10\EXPECT{\psi}{\psi}U+\PARENTESIS{p-q}\PROYECT 01\EXPECT{\psi}{\psi}{U^{\dagger}}}
\]

Lo que aparece es un valor medio cada vez más débil cuando $p\rightarrow q$. 

\[
\VALMEDIO{\sigma_{x}}=Re\CORCHETES{\EXPECT{\psi}{\psi}U}\PARENTESIS{p-q}
\]
\[
\VALMEDIO{\sigma_{y}}=Im\CORCHETES{\EXPECT{\psi}{\psi}{U^{\dagger}}}\PARENTESIS{p-q}
\]

Ahora si metemos uno completamente mezclado 
\[
\VALMEDIO{\sigma_{x}}=\PARENTESIS{p-q}Re\PARENTESIS{\frac{TrU}{2^{n}}}
\]
\[
\VALMEDIO{\sigma_{y}}=\PARENTESIS{p-q}Im\PARENTESIS{\frac{TrU}{2^{n}}}
\]

Entonces puedo hacer algunos algoritmos de forma eficiente con estados
mezclas. 

Esta es otra forma de escribir esto:

\begin{quantikz}  
\lstick{$\rho
_A$} & \gate{H} & \qw & \ctrl{1} & \qw   &\meter {} & \rstick{$\begin{matrix} \langle \sigma_x \rangle=(p-q)Re(\frac{Tr U}{2^n})\\ \langle \sigma_y \rangle=(p-q)Im(\frac{Tr U}{2^n}) \end{matrix}$} \qw  \\
\lstick{$\rho_B$} &\qwbundle[alternate]{}&\qwbundle[alternate]{}&\gate{U}\qwbundle[alternate]{} & \qwbundle[alternate]{}  
\end{quantikz} 

Es fácil de implementar con fotones. 

\section{Información mutua}

\subsection{Clásicamente }

\[
I(A,B)=S(A)+S(B)-S(A,B)
\]
propiedades

1) $I(A,B)\geq0$ siempre

2) $I(A,B)=0\iff S(A,B)=S(A)+S(B)$ 

Desde el punto de vista físico, uno piensa que si tenemos dos sistemas
que son independientes $I=0$, sino la suma es un poco mayor que la
entropía conjunto. 
\[
S(A,B)=-\sum_{ij}p_{ij}\log_{2}p_{ij}
\]
entropía de Shanon, con $p_{ij}=p(A=i,B=j)$ probabilidad de que $A=i,B=j$.
Luego 
\[
S(A)=-\sum_{i}p_{i}^{A}\log_{2}p_{i}^{A}
\]
con $p_{i}^{A}=p(A=i)=\sum_{j}p(A=i,B=j)$. De forma análoga se define
para $B$.

Si $p_{ij}=p_{i}^{A}p_{j}^{B}$ $\forall j$, $S(A,B)$

Quiero mostrar que esto es siempre positivo:

\[
I(A,B)=-\sum_{i}p_{i}^{A}\log_{2}p_{i}^{A}-\sum_{j}p_{j}^{B}\log_{2}p_{j}^{B}+\sum_{ij}p_{ij}\log_{2}p_{ij}
\]

\[
=-\sum_{i,j}p_{ij}\log_{2}\frac{p_{i}^{A}p_{j}^{B}}{p_{ij}}\geq-\sum_{i,j}p_{ij}\PARENTESIS{\frac{p_{i}^{A}p_{j}^{B}}{p_{ij}}-1}=-\sum_{i,j}p_{i}^{A}p_{j}^{B}-p_{ij}=1-1=0
\]

\[
\Rightarrow I(A,B)\geq0
\]
y es $=0$ sii $p_{ij}=p_{i}^{A}p_{j}^{B}$.

Dados A y B independientes (no correlacionados) entonces $I(A,B)=0$

Dados A y B dependientes (correlacionados) entonces $I(A,B)\geq0$

\subsection{Cuántico}

Ahora lo definimos como 
\[
I(A,B)=S\PARENTESIS{\rho_{A}}+S\PARENTESIS{\rho_{B}}-S\PARENTESIS{\rho_{AB}}
\]
con $\rho_{A}=Tr_{B}\rho_{AB}$ y $\rho_{B}=Tr_{A}\rho_{AB}$. Se
cumplen las mismas propiedades:

1) $I(A,B)\geq0$ siempre

2) $I(A,B)=0\iff\rho_{AB}=\rho_{A}\otimes\rho_{B}$ (se habla de dos
sistemas independientes cuando se cumple eso, estado producto). 

Esta medida de la información solo me distingue si es o no producto,
pero nada más.

Dem: 
\[
I(A,B)=S\PARENTESIS{\rho_{A}}+S\PARENTESIS{\rho_{B}}-S\PARENTESIS{\rho_{AB}}=-Tr\rho_{AB}\PARENTESIS{\log_{2}\PARENTESIS{\rho_{A}\otimes\rho_{B}}-\log_{2}\rho_{AB}}
\]

\[
=-\sum_{\nu}p_{\nu}\PARENTESIS{\LLAVEABAJO{\EXPECT{\nu}{\nu}{\log_{2}\PARENTESIS{\rho_{A}\otimes\rho_{B}}}}{\sum_{ij}\MODULO{\BRAKETEO{\nu}{ij}}^{2}\log_{2}p_{i}^{A}p_{j}^{B}}-\log_{2}\rho_{\nu}}
\]
Usando que el log es una función cóncava entonces 

\[
I(A,B)\ge-\sum_{\nu}p_{\nu}\PARENTESIS{\log_{2}\EXPECT{\nu}{\nu}{\rho_{A}\otimes\rho_{B}}-\log_{2}\rho_{\nu}}=-\sum_{\nu}p_{\nu}\log_{2}\frac{q_{\nu}}{p_{\nu}}\geq0
\]

La info cuántica se puede acotar por una cosa clásica.

Resumamos en un cuadro

$\begin{array}{c|c|c|c}
\rho & I(A,B) & D(A,B) & E(A,B)\\
\rho_{A}\otimes\rho_{B} & 0 & 0 & 0\\
\text{Sep (clas. correlacionados)} & >0 & 0 & 0\\
\text{Sep (no clas. correlacionados)} & >0 & >0 & 0\\
E & >0 & >0 & >0
\end{array}\left.\begin{array}{c}
\\
\\
\\
\end{array}\right\} \text{separables}$

np: no producto

\[
\rho_{AB}\begin{cases}
\begin{array}{c}
\rho_{A}\otimes\rho_{B}\subset S\\
\neq\rho_{A}\otimes\rho_{B}\begin{cases}
\begin{array}{c}
\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}\\
\text{no separables o entrelazados}
\end{array} & \begin{array}{c}
\text{o separables }S\begin{cases}
\begin{array}{c}
\text{clas. correlacionados}\\
\text{no clas. correlacionados}
\end{array}\end{cases}\\
E
\end{array}\end{cases}
\end{array}\end{cases}
\]

\[
\rho_{sep}\begin{cases}
\begin{array}{c}
\sum_{ij}\KET{ij}p_{ij}\BRA{ij}\begin{cases}
\begin{array}{c}
p_{ij}=p_{i}p_{j}\forall ij\Rightarrow\rho_{A}\otimes\rho_{B}\\
\\
\end{array} & \text{Clásicamente correl (diag en estado producto)}\end{cases}\\
\sum_{\alpha}p_{\alpha}\rho_{A}^{\alpha}\otimes\rho_{B}^{\alpha}\text{ no clásic. correl.}
\end{array}\end{cases}
\]

El discord surge para distinguir entre los separables que son clásicamente
correlacionados y no clásicamente correlacionados, en ambos casos
el entrelazamiento es cero.

Los estados mezclas que aparecen en DQC1 son los separables no clásicamente
correlacionados que tienen $D>0$. Esto fue una manera de cuantizar
eso que se puede hacer en este algoritmo fue el discord. 

\subsubsection{Ej de información mutua: Estado de Bell}

\[
\KET{\psi}=\frac{\KET{00}+\KET{11}}{\sqrt{2}}
\]

\[
I(A,B)=S\PARENTESIS{\rho_{A}}+S\PARENTESIS{\rho_{B}}-S\PARENTESIS{\rho_{AB}}=
\]

Teníamos que $\rho_{A}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11}=\frac{I_{A}}{2}$
y $\rho_{B}=\frac{1}{2}\PARENTESIS{\PROYECT 00+\PROYECT 11}=\frac{I_{B}}{2}$

Entonces 
\[
I(A,B)=1+1-0=2\ge0
\]
 Es un estado que tiene una información mutua que es mayor que la
que contiene un estado clásico que es 1. 

\chapter{Clase 10: 30/09}

\section{Discord (Zurek 2001)}

El discord se introduce para clasificar los estados separables. Medida
de cuanticidad del estado

\[
D\PARENTESIS{A|B}=\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}-S\PARENTESIS{A|B}
\]
se puede pensar como la diferencia entre 2 extensiones cuánticas de
entropía condicional. <<Entropía condicional>> (es una medida de
qué tan estan distribuidos los valores condicionales de que A tome
el valor i dado que B tomó el valor j)
\[
S\PARENTESIS{A|B}=S\PARENTESIS{A,B}-S(B)=S\PARENTESIS{\rho_{AB}}-S\PARENTESIS{\rho_{B}}
\]

Luego, esta nuevo concepto, nos traslada la definición de entropía
condicional anterior a algo cuántico de la siguiente manera en hacer
una medida en B y obtener un valor j 
\[
S\PARENTESIS{A|B_{M_{B}}}=\sum_{j}p_{j}S\PARENTESIS{A|B_{j}}
\]
con $M_{B}$ las medidas. $M_{B}=\LLAVES{\LLAVEABAJO{I_{A}\otimes\PROYECT{j_{B}}{j_{B}}}{\Pi_{j}^{B}},j=1,\dots,d_{B}}$,
con $\Pi$ proyector

$p_{j}=Tr\rho_{AB}\Pi_{j}^{B}$, luego de la medida $\rho_{AB}\rightarrow\frac{\Pi_{j}^{B}\rho_{AB}\Pi_{j}^{B}}{p_{j}}=\rho_{AB}^{j}$,
entonces $p_{j}=Tr\PARENTESIS{\Pi_{j}^{B}\rho_{AB}\Pi_{j}^{B}}$con
$p_{j}$ la probabilidad de medir $j$ en $B$.

\[
S\PARENTESIS{A|B_{M_{B}}}=\sum_{j}p_{j}S\PARENTESIS{\rho_{A|j}}
\]

\[
\rho_{A|j}=Tr_{B}\rho_{AB|j}=Tr_{B}\frac{\Pi_{j}^{B}\rho_{AB}\Pi_{j}^{B}}{p_{j}}=Tr_{B}\frac{\rho_{AB}\Pi_{j}^{B}}{p_{j}}
\]

\[
S\PARENTESIS{A|B_{M_{B}}}=\sum_{j}p_{j}S\PARENTESIS{\rho_{A|j}}\geq0\qquad\text{siempre}
\]
Esto es una redefinición de entropía condicional, que es siempre definida
positiva. 

Volviendo a la definición de discord, 
\[
D\PARENTESIS{A|B}=\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}-\PARENTESIS{S\PARENTESIS{A,B}-S(B)}\ge0
\]


\subsection{¿Cuándo se anula?}

\[
D\PARENTESIS{A|B}=0\text{ si }\begin{cases}
\begin{array}{c}
\rho_{AB}=\rho_{A}\otimes\rho_{B}\qquad\PARENTESIS{p_{ij}=p_{i}p_{j}}\\
\rho_{AB}=\sum_{ij}p_{ij}\PROYECT{ij}{ij}\text{ clásicamente correlacionados (se min para la base donde \ensuremath{\rho_{AB}} es diag)}\\
\text{semi cuánticos (clásicos) }\rho_{AB}=\sum_{j}\rho_{A|j}\otimes\PROYECT{j_{B}}{j_{B}}p_{j}
\end{array}\end{cases}
\]
El semicuántico es un caso particular donde $\rho_{A|j}$ es diagonal
$\forall j$. Todos los estados anteriores son casos particulares
de estados separables, pero no son todos los posibles casos de estados
separables. Todos estados clásicamente correlacionados nos permiten
hacer cosas clásicas en el mundo cuántico.

Luego de una medida local proyectiva en B, el 
\[
\rho_{AB}\rightarrow\rho_{AB}^{j}=\frac{\Pi_{j}^{B}\rho_{AB}\Pi_{j}^{B}}{p_{j}}=\sum_{j}\rho_{A|j}\otimes\PROYECT{j_{B}}{j_{B}}p_{j}
\]
este estado al cual colapsa el estado global es del tipo semicuántico,
porque el sistema pierde su entrelazamiento y queda del tipo separable.
Que tenga discord 0 nos esta diciendo que ya no tiene tanta cuanticidad,
porque dos interpretaciones de la entropía condicional clásica coinciden
entonces son estados tipo clásico. Una medida no sólo rompe el entrelazamiento
sino también el discord. Que el discord sea distinto de cero quiere
decir que no perdió la cuanticidad. 

El discord es mayor a cero en los restantes estados separables y en
los entrelazados. 

\subsection{¿Qué pasa para estados puros?}

Tiene que reducirse a una medida de entrelazamiento. De hecho cuando
introducimos este concepto a estados puros obtenemos la definición
de entropía de entrelazamiento.

Si $\rho_{AB}$ es puro $\PARENTESIS{\rho_{AB}\iff\rho_{AB}=\PROYECT{\psi_{AB}}{\psi_{AB}}\iff\rho_{AB}^{2}=\rho_{AB}}$
entonces $S\PARENTESIS{A,B}=S\PARENTESIS{\rho_{AB}}=0\rightarrow S(A)=S(B)\Rightarrow S\PARENTESIS{A|B}=0-S(B)=-E(A,B)\leq0$

\[
\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}=0
\]

Entonces 
\[
D\PARENTESIS{A|B}=E(A,B)
\]

Porque es 0 $\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}$,
tenemos $\KET{\psi_{AB}}=\sum_{ij}c_{ij}\PROYECT{i_{A}}{j_{B}}$,
luego $\LLAVEABAJO{I_{A}\otimes\PROYECT{j_{B}}{j_{B}}}{\Pi_{j}^{B}}\KET{\psi_{AB}}=\sum_{i}c_{ij}\PROYECT{i_{A}}{j_{B}}=\LLAVEABAJO{\PARENTESIS{\sum_{i}c_{ij}\KET{i_{A}}}}{\KET{j_{A}}}\KET{j_{B}}$
entonces

\[
p_{j}=\EXPECT{\psi_{AB}}{\psi_{AB}}{\Pi_{j}^{B}}=\sum_{i}\MODULO{c_{ij}}^{2}
\]
del lado de $A$ queda un estado puro. Luego 
\[
\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}=\sum_{j}p_{j}S\PARENTESIS{\LLAVEABAJO{\rho_{A|j}}{\PROYECT{j_{A}}{j_{A}}}}=\sum_{j}p_{j}0=0
\]


\subsection{Discord e información mutua}

$I\PARENTESIS{A,B}=S(A)+S(B)-S(A,B)=S(A)-S\PARENTESIS{A|B}$, la primera
definición que se dió de discord es 
\[
D\PARENTESIS{A|B}=I\PARENTESIS{A,B}-\text{\ensuremath{\underset{M_{B}}{M\acute{a}x}}}\PARENTESIS{I\PARENTESIS{A,B_{M_{B}}}}
\]
la información mutua contiene correlaciones cuánticas y clásicas,
entonces para definir el discord resta la correlación clásica. $D\PARENTESIS{A|B}=\REDCANCEL{S(A)}+S(B)-S(A,B)-\text{\ensuremath{\underset{M_{B}}{M\acute{a}x}}}\PARENTESIS{\REDCANCEL{S(A)}-S\PARENTESIS{A|B_{M_{B}}}}$

\[
=\underset{\LLAVES{M_{B}}}{Min}\CORCHETES{S\PARENTESIS{A|B_{M_{B}}}}-\PARENTESIS{S(A,B)-S(B)}
\]
\footnote{$-\text{\ensuremath{\underset{M_{B}}{M\acute{a}x}}}=\underset{\LLAVES{M_{B}}}{Min}$}

\subsection{Ej - ejercicio de la práctica}

Supongamos que tenemos $\rho_{AB}=p\PROYECT{\psi_{AB}}{\psi_{AB}}+\PARENTESIS{1-p}\frac{I_{AB}}{4}$,
con $\KET{\psi_{AB}}=\frac{1}{\sqrt{2}}\PARENTESIS{\KET{00}+\KET{11}}$
(estado máximamente entrelazado)

Si hay mucho ruido, te quedas sin entrelazamiento, es frágil porque
necesitas un valor umbral para que empiece a ser distinta de cero.
Discord e información mutua son muy robustos, aunque tenga ruido puedo
obtener esos valores. 
\begin{center}
\includegraphics[scale=0.3]{clase30-09}
\par\end{center}

Volviendo al cuadro de la clase pasada

\[
\begin{array}{c|c|c|c}
\rho & I(A,B) & D(A,B) & E(A,B)\\
\rho_{A}\otimes\rho_{B} & 0 & 0 & 0\\
\text{Sep (clas. correlacionados)} & >0 & 0 & 0\\
\text{Sep (no clas. correlacionados)} & >0 & >0 & 0\\
E & >0 & >0 & >0
\end{array}
\]

Ahora si ponemos un estado cc

\[
\rho_{AB}^{cc}=\frac{1}{2}\PROYECT{00}{00}+\frac{1}{2}\PROYECT{11}{11}
\]

\[
\rho_{AB}^{'}=p\rho_{AB}^{cc}+\PARENTESIS{1-p}\frac{I_{AB}}{4}
\]

no tiene discord ni entrelazamiento porque es diagonal en la base
producto. si $I(A,B)>0$, ahora el gráfico es
\begin{center}
\includegraphics[scale=0.5]{clase30-09-2}
\par\end{center}

\subsection{Propiedades del discord}

Relación de $D(A|B)$ y entrelazamiento

\[
E(A,C)=D(A|B)+S(A|B)
\]
 con $C$ un sistema que purifica $\rho_{AB}$. La purificación 

\includegraphics[scale=0.5]{clase30-09-3}

Con $\rho_{ABC}=\PROYECT{\psi_{ABC}}{\psi_{ABC}}$ puro, con $\rho_{AB}=Tr_{C}\rho_{ABC}$.
Si $\rho_{AB}=\sum_{k}\PROYECT{k_{AB}}{k_{AB}}p_{k}=Tr_{C}\PROYECT{\psi_{ABC}}{\psi_{ABC}}$,
$\KET{\psi_{ABC}}=\sum_{k}\sqrt{p_{k}}\KET{k_{AB}}\KET{k_{C}}$. $dim\HILBERT_{C}\ge dim\HILBERT_{AB}$.

\subsection{Monogamia del entrelazamiento - problema 3 de la práctica 3}

$\rho_{AB}$ un estado de 2 qubits, $E_{F}(A,B)=F\PARENTESIS{C_{A,B}}$
($E_{F}$ entropía de formación, función de la concurrencia $C_{A,B}$,
con $C_{A,B}=2\lambda_{max}\PARENTESIS R-Tr(R)$ ). Se puede ver que
$0\leq C_{AB}\leq1$, $C_{AB}=0$ sii $\KET{\psi_{AB}}$ es separable,
$C_{A,B}=1$ sii máximamente entrelazado. 

Extensión a n qubits, se puede ver que 
\[
\sum_{j\neq i}C_{i,j}^{2}\leq C_{i,resto}^{2}\leq1
\]

monogamia es porque si estas muy entrelazado con uno no lo vas a poder
estar con otros. Cuando se entrelaza con todos es débil porque tiene
que satisfacer esa cota.

Si 
\[
\begin{array}{cc}
 & \begin{array}{cccc}
00 & 01 & 10 & 11\end{array}\\
\rho_{AB}=\begin{array}{c}
00\\
01\\
10\\
11
\end{array} & \left(\begin{array}{cccc}
a & 0 & 0 & b\\
0 & c & d & 0\\
0 & d^{*} & e & 0\\
b^{*} & 0 & 0 & f
\end{array}\right)
\end{array}
\]
entonces $C_{AB}=M\acute{a}x\CORCHETES{0,2\PARENTESIS{\MODULO d-\sqrt{af}},2\PARENTESIS{\MODULO b-\sqrt{ce}}}$estoy
midiendo qué tan grande son $d$ y $b$. 

\subsubsection{Para un par de qubits 
\[
\rho_{AB}=\frac{1}{4}\protect\PARENTESIS{I_{AB}+\vec{r_{A}}\vec{\sigma_{A}}\otimes I_{B}+I_{A}\otimes\vec{\sigma_{B}}\vec{r_{B}}+\sum_{\mu,\nu}\sigma_{\mu}^{A}\otimes\sigma_{\nu}^{B}J_{\mu\nu}}
\]
}

$\VALMEDIO{\vec{r_{A}}}=\VALMEDIO{\vec{\sigma_{A}}}$, $\VALMEDIO{\vec{r_{B}}}=\VALMEDIO{\vec{\sigma_{B}}}$,
con $J_{\mu\nu}=\VALMEDIO{\sigma_{\mu}^{A}\otimes\sigma_{\nu}^{B}}$.
Para hacer tomografía necesito 15 medidas. 

Si $\rho_{AB}$ es entrelazado? puedo usar el criterio de la traspuesta
parcial $\rho_{AB}^{T_{B}}\geq0$ entonces es separable (esto vale
para 2 qubits).

\[
\rho_{AB}^{T_{B}}=\frac{1}{4}\PARENTESIS{I_{AB}+\vec{r_{A}}\vec{\sigma_{A}}\otimes I_{B}^{T_{B}}+I_{A}\otimes\vec{\sigma_{B}}^{T_{B}}\vec{r_{B}}+\sum_{\mu,\nu}\sigma_{\mu}^{A}\otimes\PARENTESIS{\sigma_{\nu}^{B}}^{T_{B}}J_{\mu\nu}}
\]

\[
\sigma_{z}=\left(\begin{array}{cc}
1 & 0\\
0 & -1
\end{array}\right)\rightarrow\sigma_{z}^{T}=\sigma_{z}
\]

\[
\sigma_{x}=\left(\begin{array}{cc}
0 & 1\\
1 & 0
\end{array}\right)\rightarrow\sigma_{x}^{T}=\sigma_{x}
\]

\[
\sigma_{y}=\left(\begin{array}{cc}
0 & 1\\
-1 & 0
\end{array}\right)\rightarrow\sigma_{y}^{T}=-\sigma_{y}=\sigma_{y}^{*}
\]

Si $\sigma_{y}$ no aparece, los $\lambda\PARENTESIS{\rho_{AB}^{T_{B}}}=\lambda\PARENTESIS{\rho_{AB}}$,
entonces no vamos a tener entrelazamiento. Necesitamos que haya correlación
entre todos los observables, entonces $Rg\PARENTESIS{J_{\mu\nu}}=3$
sino no aparece una de las tres $\sigma$ entonces $\lambda\PARENTESIS{\rho_{AB}^{T_{B}}}=\lambda\PARENTESIS{\rho_{AB}}$.
$J_{\mu\nu}$ no es necesariamente simétrica, si le hacemos la descomposición
en valores singulares la llevamos a la forma diagonal: $J=R_{A}DR_{B}^{T}$,
entonces $R_{A}^{T}JR_{D}=D=\left(\begin{array}{ccc}
J_{1} & 0 & 0\\
0 & J_{2} & 0\\
0 & 0 & J_{3}
\end{array}\right)$ de esta forma puedo sacarme cuentas de encima. 

